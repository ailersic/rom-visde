{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 09:28:18.082229: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748525298.106616 2638364 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748525298.114157 2638364 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-29 09:28:18.140794: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /trinity/home/andrew/miniconda3/envs/visde/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"../../../../..\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_reactiondiffusion import get_rd_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = get_rd_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data key: dict_keys(['t', 'y1', 'y2', 'x', 'dx'])\n",
      "Training data t shape: (7999, 1)\n",
      "Training data x shape: (7999, 10000)\n",
      "Training data dx shape: (7999, 10000)\n",
      "Training data y1 shape: (100, 1)\n",
      "Training data y2 shape: (100, 1)\n",
      "Validation data key: dict_keys(['t', 'y1', 'y2', 'x', 'dx'])\n",
      "Test data key: dict_keys(['t', 'y1', 'y2', 'x', 'dx'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training data key:\", training_data.keys())\n",
    "print(\"Training data t shape:\", training_data['t'].shape)\n",
    "print(\"Training data x shape:\", training_data['x'].shape)\n",
    "print(\"Training data dx shape:\", training_data['dx'].shape)\n",
    "print(\"Training data y1 shape:\", training_data['y1'].shape)\n",
    "print(\"Training data y2 shape:\", training_data['y2'].shape)\n",
    "print(\"Validation data key:\", validation_data.keys())\n",
    "print(\"Test data key:\", test_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params['input_dim'] = training_data['y1'].size*training_data['y2'].size\n",
    "params['latent_dim'] = 2\n",
    "params['model_order'] = 1\n",
    "params['poly_order'] = 3\n",
    "params['include_sine'] = True\n",
    "params['library_dim'] = library_size(params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_z'] = 0.01\n",
    "params['loss_weight_sindy_x'] = 0.5\n",
    "params['loss_weight_sindy_regularization'] = 0.1\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [256]\n",
    "\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['t'].size\n",
    "params['batch_size'] = 1000\n",
    "params['learning_rate'] = 1e-3\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 100\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 3001\n",
    "params['refinement_epochs'] = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n",
      "TRAINING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748525338.898948 2638364 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18934 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:82:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748525338.927709 2638364 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "   training loss 5.075778961181641, (0.16202483, 474.169, 0.14433075, 0.99898535)\n",
      "   validation loss 5.137853145599365, (0.16235298, 480.33524, 0.14449866, 0.99898535)\n",
      "decoder loss ratio: 1.024982, decoder SINDy loss  ratio: 1.105488\n",
      "Epoch 100\n",
      "   training loss 0.2377086579799652, (0.084470026, 1.8683292, 0.073317625, 0.9789653)\n",
      "   validation loss 0.23892737925052643, (0.085259676, 1.9381658, 0.07277902, 0.9789653)\n",
      "decoder loss ratio: 0.538269, decoder SINDy loss  ratio: 0.556797\n",
      "Epoch 200\n",
      "   training loss 0.2043123096227646, (0.068523966, 0.8636147, 0.06489827, 0.9470306)\n",
      "   validation loss 0.20611104369163513, (0.06945649, 0.87652236, 0.06637253, 0.9470306)\n",
      "decoder loss ratio: 0.438499, decoder SINDy loss  ratio: 0.507784\n",
      "Epoch 300\n",
      "   training loss 0.1773369312286377, (0.054198507, 0.5393707, 0.054120626, 0.9068441)\n",
      "   validation loss 0.18002718687057495, (0.055611443, 0.53997606, 0.056663156, 0.9068441)\n",
      "decoder loss ratio: 0.351091, decoder SINDy loss  ratio: 0.433502\n",
      "Epoch 400\n",
      "   training loss 0.15995024144649506, (0.04809575, 0.30763048, 0.047915723, 0.8482032)\n",
      "   validation loss 0.16242656111717224, (0.049463373, 0.30513895, 0.050182957, 0.8482032)\n",
      "decoder loss ratio: 0.312277, decoder SINDy loss  ratio: 0.383925\n",
      "Epoch 500\n",
      "   training loss 0.142794668674469, (0.034472678, 0.15722583, 0.053438045, 0.80030704)\n",
      "   validation loss 0.14511337876319885, (0.035546478, 0.15679456, 0.05593652, 0.80030704)\n",
      "decoder loss ratio: 0.224415, decoder SINDy loss  ratio: 0.427943\n",
      "THRESHOLDING: 24 active coefficients\n",
      "Epoch 600\n",
      "   training loss 0.09620586782693863, (0.0054251486, 0.015854737, 0.022550981, 0.7934668)\n",
      "   validation loss 0.09677673876285553, (0.005572247, 0.016011592, 0.023395386, 0.7934668)\n",
      "decoder loss ratio: 0.035179, decoder SINDy loss  ratio: 0.178987\n",
      "Epoch 700\n",
      "   training loss 0.08458790928125381, (0.002484964, 0.0010307883, 0.0028658577, 0.80659705)\n",
      "   validation loss 0.08465369045734406, (0.002498662, 0.0010177809, 0.0029702864, 0.80659705)\n",
      "decoder loss ratio: 0.015775, decoder SINDy loss  ratio: 0.022724\n",
      "Epoch 800\n",
      "   training loss 0.08144008368253708, (0.0024489593, 0.0007323524, 0.0027247125, 0.7762144)\n",
      "   validation loss 0.08150883764028549, (0.0024704228, 0.0007267141, 0.002819407, 0.7762144)\n",
      "decoder loss ratio: 0.015596, decoder SINDy loss  ratio: 0.021570\n",
      "Epoch 900\n",
      "   training loss 0.07726358622312546, (0.0024352828, 0.00056139653, 0.0026257676, 0.73509806)\n",
      "   validation loss 0.0773354172706604, (0.002461429, 0.0005615746, 0.0027171387, 0.73509806)\n",
      "decoder loss ratio: 0.015540, decoder SINDy loss  ratio: 0.020787\n",
      "Epoch 1000\n",
      "   training loss 0.07158032059669495, (0.0024315673, 0.0004533745, 0.0026394522, 0.6782449)\n",
      "   validation loss 0.07165168225765228, (0.0024607345, 0.0004548791, 0.0027238105, 0.6782449)\n",
      "decoder loss ratio: 0.015535, decoder SINDy loss  ratio: 0.020839\n",
      "THRESHOLDING: 23 active coefficients\n",
      "Epoch 1100\n",
      "   training loss 0.0637294352054596, (0.0024861295, 0.00036480874, 0.0025464392, 0.5996644)\n",
      "   validation loss 0.06380071491003036, (0.0025143845, 0.00036376793, 0.002632501, 0.5996644)\n",
      "decoder loss ratio: 0.015874, decoder SINDy loss  ratio: 0.020140\n",
      "Epoch 1200\n",
      "   training loss 0.055879734456539154, (0.0024753183, 0.00028357166, 0.0024544816, 0.5217434)\n",
      "   validation loss 0.05595151335000992, (0.002502422, 0.00029343713, 0.0025436338, 0.5217434)\n",
      "decoder loss ratio: 0.015799, decoder SINDy loss  ratio: 0.019460\n",
      "Epoch 1300\n",
      "   training loss 0.050665419548749924, (0.0024710405, 0.00031964338, 0.0026708406, 0.46855763)\n",
      "   validation loss 0.0507170706987381, (0.0024955873, 0.00032737773, 0.0027248953, 0.46855763)\n",
      "decoder loss ratio: 0.015755, decoder SINDy loss  ratio: 0.020847\n",
      "Epoch 1400\n",
      "   training loss 0.046290673315525055, (0.0024343573, 0.00032572992, 0.0026418061, 0.42532158)\n",
      "   validation loss 0.04634001851081848, (0.0024592264, 0.00031837914, 0.0026909013, 0.42532158)\n",
      "decoder loss ratio: 0.015526, decoder SINDy loss  ratio: 0.020587\n",
      "Epoch 1500\n",
      "   training loss 0.04320412501692772, (0.0028937794, 0.0011264799, 0.0027181741, 0.38939992)\n",
      "   validation loss 0.04328399896621704, (0.002947064, 0.0010970042, 0.0027719457, 0.38939992)\n",
      "decoder loss ratio: 0.018606, decoder SINDy loss  ratio: 0.021207\n",
      "THRESHOLDING: 11 active coefficients\n",
      "Epoch 1600\n",
      "   training loss 0.0413677841424942, (0.0024334956, 0.00031528372, 0.0026251727, 0.3761855)\n",
      "   validation loss 0.041425254195928574, (0.0024644823, 0.00030977186, 0.0026782437, 0.3761855)\n",
      "decoder loss ratio: 0.015559, decoder SINDy loss  ratio: 0.020490\n",
      "Epoch 1700\n",
      "   training loss 0.04050305485725403, (0.0025888034, 0.0006066065, 0.0026302803, 0.36593044)\n",
      "   validation loss 0.04055195301771164, (0.002615527, 0.0005846454, 0.0026750667, 0.36593044)\n",
      "decoder loss ratio: 0.016513, decoder SINDy loss  ratio: 0.020466\n",
      "Epoch 1800\n",
      "   training loss 0.03907957673072815, (0.0024826166, 0.0014006227, 0.0029507978, 0.35107556)\n",
      "   validation loss 0.03913172334432602, (0.0025085136, 0.001500402, 0.0030012995, 0.35107556)\n",
      "decoder loss ratio: 0.015837, decoder SINDy loss  ratio: 0.022961\n",
      "Epoch 1900\n",
      "   training loss 0.03787272796034813, (0.0032739635, 0.0033651108, 0.002918779, 0.33105722)\n",
      "   validation loss 0.03793203458189964, (0.0033214039, 0.0032819223, 0.0029441782, 0.33105722)\n",
      "decoder loss ratio: 0.020969, decoder SINDy loss  ratio: 0.022524\n",
      "Epoch 2000\n",
      "   training loss 0.03407282754778862, (0.0024970416, 0.0009464724, 0.0026600817, 0.3023628)\n",
      "   validation loss 0.03412531688809395, (0.0025262004, 0.000997044, 0.0027057333, 0.3023628)\n",
      "decoder loss ratio: 0.015949, decoder SINDy loss  ratio: 0.020700\n",
      "THRESHOLDING: 10 active coefficients\n",
      "Epoch 2100\n",
      "   training loss 0.030072741210460663, (0.0026574926, 0.0012333218, 0.0024500212, 0.26177904)\n",
      "   validation loss 0.030140962451696396, (0.0026963537, 0.0013750511, 0.0025059101, 0.26177904)\n",
      "decoder loss ratio: 0.017023, decoder SINDy loss  ratio: 0.019171\n",
      "Epoch 2200\n",
      "   training loss 0.02482880838215351, (0.0029607276, 0.0044223624, 0.0026928016, 0.20477457)\n",
      "   validation loss 0.024905409663915634, (0.0030083298, 0.004522379, 0.0027487986, 0.20477457)\n",
      "decoder loss ratio: 0.018992, decoder SINDy loss  ratio: 0.021030\n",
      "Epoch 2300\n",
      "   training loss 0.016923099756240845, (0.0029179605, 0.0030292205, 0.0025475905, 0.12701052)\n",
      "   validation loss 0.01701781339943409, (0.002980221, 0.0030612932, 0.0026118534, 0.12701052)\n",
      "decoder loss ratio: 0.018815, decoder SINDy loss  ratio: 0.019982\n",
      "Epoch 2400\n",
      "   training loss 0.011219356209039688, (0.0025237163, 0.0028834848, 0.0025152918, 0.07409159)\n",
      "   validation loss 0.011274123564362526, (0.0025345364, 0.0032365047, 0.002596127, 0.07409159)\n",
      "decoder loss ratio: 0.016001, decoder SINDy loss  ratio: 0.019862\n",
      "Epoch 2500\n",
      "   training loss 0.01094738394021988, (0.0026695202, 0.005408994, 0.0023605458, 0.07043501)\n",
      "   validation loss 0.011003307066857815, (0.0027064397, 0.005414458, 0.0023984436, 0.07043501)\n",
      "decoder loss ratio: 0.017087, decoder SINDy loss  ratio: 0.018349\n",
      "THRESHOLDING: 2 active coefficients\n",
      "Epoch 2600\n",
      "   training loss 0.010821066796779633, (0.0025488334, 0.005889991, 0.0023234102, 0.07051629)\n",
      "   validation loss 0.010881070047616959, (0.0025727039, 0.0065148915, 0.0023831776, 0.07051629)\n",
      "decoder loss ratio: 0.016242, decoder SINDy loss  ratio: 0.018233\n",
      "Epoch 2700\n",
      "   training loss 0.01085679978132248, (0.0025720943, 0.004480512, 0.002354529, 0.07062636)\n",
      "   validation loss 0.010912996716797352, (0.0026085638, 0.004650179, 0.002390589, 0.07062636)\n",
      "decoder loss ratio: 0.016469, decoder SINDy loss  ratio: 0.018289\n",
      "Epoch 2800\n",
      "   training loss 0.010733849368989468, (0.0024498075, 0.002196518, 0.0023464984, 0.07088827)\n",
      "   validation loss 0.01078225951641798, (0.002469693, 0.0025225813, 0.0023970269, 0.07088827)\n",
      "decoder loss ratio: 0.015592, decoder SINDy loss  ratio: 0.018338\n",
      "Epoch 2900\n",
      "   training loss 0.010744856670498848, (0.0024345224, 0.002163866, 0.0023818891, 0.07097751)\n",
      "   validation loss 0.01079430803656578, (0.0024585102, 0.0024065413, 0.0024279626, 0.07097751)\n",
      "decoder loss ratio: 0.015521, decoder SINDy loss  ratio: 0.018575\n",
      "Epoch 3000\n",
      "   training loss 0.011627882719039917, (0.002642843, 0.058768585, 0.0025843417, 0.07105183)\n",
      "   validation loss 0.011718536727130413, (0.002678032, 0.062410135, 0.0026224412, 0.07105183)\n",
      "decoder loss ratio: 0.016907, decoder SINDy loss  ratio: 0.020063\n",
      "THRESHOLDING: 2 active coefficients\n",
      "REFINEMENT\n",
      "Epoch 0\n",
      "   training loss 0.018101071938872337, (0.011125577, 0.47215575, 0.004507878, 0.07111702)\n",
      "   validation loss 0.01792200095951557, (0.011009603, 0.46031964, 0.0046184016, 0.07111702)\n",
      "decoder loss ratio: 0.069507, decoder SINDy loss  ratio: 0.035333\n",
      "Epoch 100\n",
      "   training loss 0.003407031064853072, (0.0023795452, 0.0061642462, 0.0019316869, 0.077284954)\n",
      "   validation loss 0.003472941229119897, (0.0024049887, 0.006812685, 0.001999651, 0.077284954)\n",
      "decoder loss ratio: 0.015183, decoder SINDy loss  ratio: 0.015298\n",
      "Epoch 200\n",
      "   training loss 0.0033813065383583307, (0.0023890252, 0.0030598235, 0.0019233664, 0.07746572)\n",
      "   validation loss 0.0034432068932801485, (0.0024153688, 0.0032600188, 0.0019904757, 0.07746572)\n",
      "decoder loss ratio: 0.015249, decoder SINDy loss  ratio: 0.015228\n",
      "Epoch 300\n",
      "   training loss 0.0034161878284066916, (0.00238981, 0.0071831383, 0.001909093, 0.07784141)\n",
      "   validation loss 0.0034668203443288803, (0.002413488, 0.006472401, 0.0019772167, 0.07784141)\n",
      "decoder loss ratio: 0.015237, decoder SINDy loss  ratio: 0.015127\n",
      "Epoch 400\n",
      "   training loss 0.003307958832010627, (0.0023589404, 0.00082974037, 0.001881442, 0.078704424)\n",
      "   validation loss 0.003367539495229721, (0.002383183, 0.0010497443, 0.0019477183, 0.078704424)\n",
      "decoder loss ratio: 0.015046, decoder SINDy loss  ratio: 0.014901\n",
      "Epoch 500\n",
      "   training loss 0.0033322179224342108, (0.0023748388, 0.0016052974, 0.0018826523, 0.07889766)\n",
      "   validation loss 0.0033917613327503204, (0.0023985836, 0.0019066662, 0.0019482223, 0.07889766)\n",
      "decoder loss ratio: 0.015143, decoder SINDy loss  ratio: 0.014905\n",
      "Epoch 600\n",
      "   training loss 0.0033323951065540314, (0.0023738171, 0.0018322697, 0.0018805107, 0.08008876)\n",
      "   validation loss 0.003392190206795931, (0.0023983903, 0.0020327521, 0.0019469447, 0.08008876)\n",
      "decoder loss ratio: 0.015142, decoder SINDy loss  ratio: 0.014895\n",
      "Epoch 700\n",
      "   training loss 0.003574107075110078, (0.002390805, 0.023574311, 0.0018951182, 0.080328755)\n",
      "   validation loss 0.0036674663424491882, (0.002420065, 0.02657103, 0.0019633821, 0.080328755)\n",
      "decoder loss ratio: 0.015279, decoder SINDy loss  ratio: 0.015021\n",
      "Epoch 800\n",
      "   training loss 0.0033815926872193813, (0.0024140975, 0.0024856569, 0.001885277, 0.08094664)\n",
      "   validation loss 0.003438019659370184, (0.00243655, 0.0026178819, 0.0019505814, 0.08094664)\n",
      "decoder loss ratio: 0.015383, decoder SINDy loss  ratio: 0.014923\n",
      "Epoch 900\n",
      "   training loss 0.0032989978790283203, (0.002353886, 0.00076810777, 0.0018748615, 0.08337443)\n",
      "   validation loss 0.003360712667927146, (0.002379365, 0.0011336461, 0.0019400222, 0.08337443)\n",
      "decoder loss ratio: 0.015022, decoder SINDy loss  ratio: 0.014842\n",
      "Epoch 1000\n",
      "   training loss 0.0033051075879484415, (0.0023596254, 0.0008886197, 0.001873192, 0.08331375)\n",
      "   validation loss 0.003368123434484005, (0.0023857986, 0.0012271217, 0.0019401072, 0.08331375)\n",
      "decoder loss ratio: 0.015062, decoder SINDy loss  ratio: 0.014843\n",
      "Experiment 0 completed in 5769.60 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "num_experiments = 1\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "\n",
    "    params['save_name'] = 'model_noisy'#'rd_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    results_dict = train_network(training_data, validation_data, params)\n",
    "    #df = pd.concat([df, {**results_dict, **params}])\n",
    "    new_row = pd.DataFrame([{**results_dict, **params}])\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "    print('Experiment %d completed in %.2f seconds' % (i, time.time() - start_time))\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
